<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chengwei Zhao</title>
  
  <meta name="author" content="Chengwei Zhao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chengwei Zhao</name>
              </p>
              <p> I am  an autonomous driving practitioners in HangZhou.
              </p>
              <p></p>
              <p>
              My research interests include LiDAR-based Simultaneous Localization and Mapping (SLAM), Lifelong Mapping, and Global Localization, with a focus on developing robust and efficient algorithms for autonomous navigation and mapping in dynamic environments. I am particularly interested in leveraging multi-session sensor data with temporal variations for reliable autonomy.
              </p>
              <p style="text-align:center">
                <a href="chengweizhao0427@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.com/citations?user=t_5U_98AAAAJ&hl=ko&oi=ao">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://github.com/chengwei0427">Github</a> &nbsp/&nbsp
                <a href="https://space.bilibili.com/38956861?spm_id_from=333.1007.0.0">bilibili</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/cc0.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/cc0.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <!-- <p>
              Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cc-2025-ral.png" alt="II_NVM" width="160">
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/chengwei0427/II-NVM">
                <span class="papertitle">II-NVM: Enhancing Map Accuracy and Consistency with Normal Vector-Assisted Mapping</span>
            </a>
            <br>
            <strong>Chengwei Zhao*</strong>,
            <a href="https://github.com/bojackhomeman"> Yixuan Li*</a>,
            <a>Yina Jian</a>,
            <a href="https://github.com/jiejie567">Jie Xu‚Ä†</a>,
            <a>Linji Wang</a>,
            <a>Yongxin Ma</a>,
            <a>Xinglai Jin</a>
            <br>
            <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2025
            <br>
            <!-- [<a href="">paper</a>] -->
            [<a href="https://arxiv.org/abs/2504.08204">arXiv</a>]
            [<a href="https://github.com/chengwei0427/II-NVM">code</a>]
            <p></p>
            <p>
              II-NVM is a Normal Vector-Assisted Mapping framework that enhance the voxel map structure to store both point cloud data and normal vector information, enabling the system to evaluate consistency during nearest neighbor searches and map updates. This process distinguishes between the front and back sides of surfaces, preventing incorrect point-to-plane constraints. Moreover, we implement an adaptive radius KD-tree search method that dynamically adjusts the search radius based on the local density of the point cloud, thereby enhancing the accuracy of normal vector calculations. To further improve real time performance and storage efficiency, we incorporate a Least Recently Used (LRU) cache strategy, which facilitates efficient incremental updates of the voxel map.
            </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cc-2024-jiot.png" alt="Adaptive-lio" width="160">
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/chengwei0427/Adaptive-LIO">
                <span class="papertitle">Adaptive-LIO: Enhancing Robustness and Precision through Environmental Adaptation in LiDAR Inertial Odometry</span>
            </a>
            <br>
            <strong>Chengwei Zhao*</strong>,
            <a href="https://github.com/KJ-Falloutlast">Kun Hu*</a>,
            <a href="https://github.com/jiejie567">Jie Xu‚Ä†</a>,
            <a href="https://orcid.org/0000-0002-9108-8276">Lijun Zhao‚Ä†</a>,
            <a href="https://orcid.org/0009-0009-0503-8810">Baiwen Han</a>,
            <a href="https://orcid.org/0009-0005-3938-7454">Kaidi Wu</a>,
            <a href="https://orcid.org/0009-0007-0403-8961">Maoshan Tian</a>,
            <a href="https://github.com/snakehaihai">Shenghai Yuan</a>
            <br>
            <em>IEEE Internet of Things Journal</em>, 2024
            <br>
            [<a href="https://ieeexplore.ieee.org/document/10806842">paper</a>]
            [<a href="https://arxiv.org/abs/2503.05077">arXiv</a>]
            [<a href="https://github.com/chengwei0427/Adaptive-LIO">code</a>]
            <p></p>
            <p>
            Adaptive-LIO is a loosely coupled adaptive LiDAR-Inertial-Odometry, which incorporates adaptive segmentation to enhance mapping accuracy, adapts motion modality through IMU saturation and fault detection, and adjusts map resolution adaptively using multi-resolution voxel maps based on the distance from the LiDAR center. Our proposed method has been tested in various challenging scenarios, demonstrating the effectiveness of the improvements we introduce.
            </p>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/djlee-2024-isr.png" alt="LiDAR-odometry-survey" width="160">
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">LiDAR odometry survey: recent advancements and remaining challenges</span>
            <br>
            <strong>Dongjae Lee</strong>,
            <a href="https://scholar.google.com/citations?user=aKPTi7gAAAAJ&hl=ko">Minwoo Jung</a>,
            <a href="https://scholar.google.com/citations?user=lh2KUKMAAAAJ&hl=en">Wooseong Yang</a>,
            <a href="https://ayoungk.github.io/">Ayoung Kim</a>
            <br>
            <em>Intelligent Service Robotics</em>, 2024
            <br>
            [<a href="https://link.springer.com/article/10.1007/s11370-024-00515-8">paper</a>]
            <p></p>
            <p>
            A survey paper on LiDAR odometry, including a comprehensive review of recent advancements and remaining challenges.
            </p>
            </td>
          </tr> -->


        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Other publications and projects</heading>
            <!-- <p>
            Representative papers are <span class="highlight">highlighted</span>.
            </p> -->
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/cc-2024-iros.png" alt="I2EKF-LO" width="160">
          </td>

          <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/YWL0720/I2EKF-LO">
              <span class="papertitle">I2EKF-LO: A Dual-Iteration Extended Kalman Filter Based LiDAR Odometry</span>
          </a>
          <br> 
          <a href="https://github.com/YWL0720"> Wenlu Yu*</a>, 
          <a href="https://github.com/jiejie567">Jie Xu*</a>,
          <strong>Chengwei Zhao</strong>,
          <a href="https://orcid.org/0000-0002-9108-8276">Lijun Zhao‚Ä†</a>,
          <a href="https://github.com/">Thien-Minh Nguyen</a>,
          <a href="https://github.com/snakehaihai">Shenghai Yuan</a>,
          <a href="https://github.com/">Mingming Bai</a>,
          <a href="https://github.com/">Lihua Xie</a>
          <br>
          <em>IEEE/RJS International Conference on Intelligent RObots and Systems (IROS)</em>, 2024 
          <br>
          [<a href="https://arxiv.org/abs/2407.02190">arXiv</a>]
          [<a href="https://github.com/YWL0720/I2EKF-LO">code</a>]
          <p></p>
          <p>
          I2EKF-LO is a Dual-Iteration Extended Kalman Filter (I2EKF) and the LiDAR odometry, this approach not only iterates over the observation equation but also leverages state updates to iteratively mitigate motion distortion in LiDAR point clouds. Moreover, it dynamically adjusts process noise based on the confidence level of prior predictions during state estimation and establishes motion models for different sensor carriers to achieve accurate and efficient state estimation. Comprehensive experiments demonstrate that I2EKF-LO achieves outstanding levels of accuracy and computational efficiency in the realm of LiDAR odometry.
          </p>
          </td>
        </tr>

        <!-- <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/hjgil-2023-jkros.png" alt="gnss-lidar-inertial" width="160">
          </td>

          <td style="padding:20px;width:75%;vertical-align:middle">
          <span class="papertitle">Tightly-coupled gnss-lidar-inertial state estimator for mapping and autonomous driving</span>
          <br>
          <a href="https://scholar.google.com/citations?user=n15gehEAAAAJ&hl=ko">Hyeonjae Gil</a>,
          <strong>Dongjae Lee</strong>,
          Gwanhyeong Song,
          Seunguk Ahn,
          <a href="https://ayoungk.github.io/">Ayoung Kim</a>
          <br>
          <em>The Journal of Korea Robotics Society</em>, 2023 <font color="red"><strong>(Best paper award)</strong></font>
          <br>
          [<a href="https://jkros.org/xml/35751/35751.pdf">paper</a>]
          <p></p>
          <p>
          Tightly-coupled GNSS-LiDAR-Inertial state estimator for SLAM and autonomous driving, addressing long-term drift through the integration of raw GNSS measurements, which ensures smooth and accurate state estimation.
          </p>
          </td>
        </tr> -->


      </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Template by Jon Barron.</a>
             </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
